import streamlit as st
import media_edit  # üé¨ –í–∏–¥–µ–æ –∑–∞—Å–≤–∞—Ä–ª–∞–≥—á –º–æ–¥—É–ª–∏–π–≥ –¥—É—É–¥–∞–∂ –±–∞–π–Ω–∞

st.sidebar.title("üéõ –ù—ç–º—ç–ª—Ç —Ö—ç—Ä—ç–≥—Å—ç–ª")
menu = st.sidebar.radio("–°–æ–Ω–≥–æ—Ö:", ["ü§ñ AI —á–∞—Ç", "üé¨ –í–∏–¥–µ–æ –∑–∞—Å–≤–∞—Ä–ª–∞–≥—á"])

if menu == "üé¨ –í–∏–¥–µ–æ –∑–∞—Å–≤–∞—Ä–ª–∞–≥—á":
    media_edit.media_edit_ui()
else:
    st.header("ü§ñ –¢“Ø–º—ç–Ω–∂–∞—Ä–≥–∞–ª—ã–Ω Hybrid AI System")
    st.write("Local Ollama + Memory + Chat Interface")
import streamlit as st
import requests
import json
import os
from datetime import datetime

OLLAMA_URL = "http://127.0.0.1:11434/api/generate"
MEMORY_FILE = "memory/memory.json"

# --- –¢—É—Å–ª–∞—Ö —Ñ—É–Ω–∫—Ü“Ø“Ø–¥ ---
def load_memory():
    if not os.path.exists(MEMORY_FILE):
        os.makedirs("memory", exist_ok=True)
        return []
    with open(MEMORY_FILE, "r") as f:
        return json.load(f)

def save_memory(memory):
    with open(MEMORY_FILE, "w") as f:
        json.dump(memory, f, indent=2, ensure_ascii=False)

def query_ollama(prompt):
    payload = {"model": "llama3.1", "prompt": prompt}
    response = requests.post(OLLAMA_URL, json=payload, stream=True)
    reply = ""
    for line in response.iter_lines():
        if line:
            data = json.loads(line.decode("utf-8"))
            if "response" in data:
                reply += data["response"]
    return reply.strip()

# --- UI —Ö—ç—Å—ç–≥ ---
st.set_page_config(page_title="Hybrid AI Assistant", layout="wide")
st.title("ü§ñ –¢“Ø–º—ç–Ω–∂–∞—Ä–≥–∞–ª—ã–Ω Hybrid AI System")
st.markdown("**Local Ollama + Memory + Streamlit Interface**")

memory = load_memory()

with st.sidebar:
    st.header("üß† AI Memory")
    if st.button("Clear Memory"):
        save_memory([])
        st.success("AI —Å–∞–Ω–∞—Ö –æ–π–≥ —Ü—ç–≤—ç—Ä–ª—ç–ª—ç—ç ‚úÖ")
    st.write("”®–º–Ω”©—Ö —è—Ä–∏–ª—Ü–ª–∞–≥—É—É–¥:")
    for item in memory[-5:]:
        st.write(f"- {item['user'][:40]}...")

user_input = st.text_area("üó®Ô∏è –¢–µ–∫—Å—Ç—ç—ç –æ—Ä—É—É–ª–Ω–∞ —É—É:", placeholder="AI-–¥ –∞—Å—É—É–ª—Ç —ç—Å–≤—ç–ª –∫–æ–º–∞–Ω–¥ –±–∏—á...")
if st.button("–ò–ª–≥—ç—ç—Ö"):
    st.write("‚è≥ –•–∞—Ä–∏—É–ª–∂ –±–∞–π–Ω–∞...")
    ai_response = query_ollama(user_input)
    st.markdown(f"### ü§ñ –•–∞—Ä–∏—É–ª—Ç:\n{ai_response}")

    # –°–∞–Ω–∞—Ö –æ–π —Ö–∞–¥–≥–∞–ª–∞—Ö
    memory.append({"time": str(datetime.now()), "user": user_input, "ai": ai_response})
    save_memory(memory)
    st.success("–•–∞—Ä–∏—É–ª—Ç –∞–º–∂–∏–ª—Ç—Ç–∞–π —Ö–∞–¥–≥–∞–ª–∞–≥–¥–ª–∞–∞ ‚úÖ")
import streamlit as st
from hybrid_chatbot import chat_with_ai  # —ç—Å–≤—ç–ª ”©”©—Ä –≥–æ–ª —Ñ—É–Ω–∫—Ü—ç—ç —ç–Ω–¥ –∏–º–ø–æ—Ä—Ç–ª–æ–æ—Ä–æ–π

def main():
    st.title("ü§ñ Hybrid AI Assistant")
    st.write("–¢–∞–≤—Ç–∞–π –º–æ—Ä–∏–ª Tumka28! üöÄ")
    
    user_input = st.text_input("–Ø–º–∞—Ä –∞—Å—É—É–ª—Ç –±–∞–π–Ω–∞?")
    if st.button("AI —Ö–∞—Ä–∏—É–ª–∞—Ö"):
        if user_input:
            response = chat_with_ai(user_input)
            st.success(response)
        else:
            st.warning("–Æ—É –±–∏—á–∏—Ö—ç—ç –æ—Ä—É—É–ª–Ω–∞ —É—É!")

if __name__ == "__main__":
    main()
