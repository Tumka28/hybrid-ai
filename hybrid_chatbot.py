import streamlit as st
import requests
import sqlite3
import os
from datetime import datetime

# --- –¢–æ—Ö–∏—Ä–≥–æ–æ ---
OLLAMA_URL = "http://localhost:11434/api/generate"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")  # export OPENAI_API_KEY="—Ç“Ø–ª—Ö“Ø“Ø—Ä"
DB_PATH = "memory.db"

# --- –°–∞–Ω–∞—Ö –æ–π “Ø“Ø—Å–≥—ç—Ö ---
conn = sqlite3.connect(DB_PATH, check_same_thread=False)
cur = conn.cursor()
cur.execute("""
CREATE TABLE IF NOT EXISTS memory (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    role TEXT,
    content TEXT,
    time TEXT
)
""")
conn.commit()

# --- –•–∞—Ä–∏—É–ª—Ç –±–∏—á–∏—Ö —Ñ—É–Ω–∫—Ü ---
def save_memory(role, content):
    cur.execute("INSERT INTO memory (role, content, time) VALUES (?, ?, ?)",
                (role, content, str(datetime.now())))
    conn.commit()

# --- Chat –ª–æ–≥ –∞–≤–∞—Ö ---
def load_memory():
    cur.execute("SELECT role, content FROM memory ORDER BY id DESC LIMIT 20")
    return cur.fetchall()[::-1]

# --- Ollama AI (offline) ---
def ask_ollama(prompt):
    try:
        response = requests.post(OLLAMA_URL, json={
            "model": "llama3",
            "prompt": prompt,
            "stream": False
        }, timeout=20)
        return response.json().get("response", "Ollama —Ö–∞—Ä–∏—É –∏—Ä—Å—ç–Ω–≥“Ø–π.")
    except Exception as e:
        return f"Ollama –∞–ª–¥–∞–∞: {e}"

# --- OpenAI GPT (online) ---
def ask_openai(prompt):
    try:
        headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}
        data = {
            "model": "gpt-4o-mini",
            "messages": [{"role": "user", "content": prompt}]
        }
        res = requests.post("https://api.openai.com/v1/chat/completions",
                            headers=headers, json=data, timeout=20)
        return res.json()["choices"][0]["message"]["content"]
    except Exception as e:
        return f"OpenAI –∞–ª–¥–∞–∞: {e}"

# --- Streamlit UI ---
st.set_page_config(page_title="Hybrid AI Chat", page_icon="ü§ñ")
st.title("ü§ñ Hybrid AI Chat ‚Äî OpenAI + Ollama")
st.write("–ò–Ω—Ç–µ—Ä–Ω–µ—Ç—Ç—ç–π “Ø–µ–¥ GPT-4 –∞—à–∏–≥–ª–∞–Ω–∞, –æ—Ñ—Ñ–ª–∞–π–Ω “Ø–µ–¥ Ollama –∞–∂–∏–ª–ª–∞–Ω–∞.")

# --- –•—É—É—á–∏–Ω —è—Ä–∏–∞–≥ —Ö–∞—Ä—É—É–ª–∞—Ö ---
for role, msg in load_memory():
    if role == "user":
        st.markdown(f"üßë **–¢–∞:** {msg}")
    else:
        st.markdown(f"ü§ñ **AI:** {msg}")

prompt = st.chat_input("–ê—Å—É—É—Ö –∑“Ø–π–ª—ç—ç –±–∏—á–Ω—ç “Ø“Ø...")

if prompt:
    save_memory("user", prompt)
    with st.spinner("AI —Ö–∞—Ä–∏—É –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∂ –±–∞–π–Ω–∞..."):
        if OPENAI_API_KEY:
            reply = ask_openai(prompt)
        else:
            reply = ask_ollama(prompt)
    st.markdown(f"ü§ñ **AI:** {reply}")
    save_memory("assistant", reply)
import requests
import json

def chat_with_ai(prompt):
    """
    Local Ollama API —ç—Å–≤—ç–ª chatbot —Å–µ—Ä–≤–µ—Ä —Ä“Ø“Ø —Ç–µ–∫—Å—Ç –∏–ª–≥—ç—ç–∂ —Ö–∞—Ä–∏—É –∞–≤–Ω–∞.
    """
    try:
        url = "http://127.0.0.1:11434/api/generate"
        payload = {"model": "llama3.1", "prompt": prompt}
        response = requests.post(url, json=payload, stream=True)

        reply = ""
        for line in response.iter_lines():
            if line:
                data = json.loads(line.decode("utf-8"))
                if "response" in data:
                    reply += data["response"]
        return reply.strip() or "‚ö†Ô∏è AI-–∞–∞—Å —Ö–∞—Ä–∏—É –∏—Ä—Å—ç–Ω–≥“Ø–π."
    except Exception as e:
        return f"‚ùå –ê–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞: {e}"
